TODO:

raytracing the next week: page 16
start PBRT book
HDR and tone-mapping
progressive rendering

Optimizations To-Do:
	General:
		don't calculate position + normal for each nearer object, instead store object ID
		  and calculate after we have found the nearest object.

		better BVH building
			cache boxes on all objects?

		SIMD
			lane-aware BVH, have leaves potentially contain LANE_WIDTH objects?
				pass to callback function to coalesce to object?
				this would make us have a BVH per object type, which isn't ideal, but
				could be worth it? of course, we can also just say you have to build
				sphere_lanes with specially near spheres and submit them as normal 
				objects to the BVH
			sphere_moving_lane
			aabb_lane

		looking into ray_lane again (didn't work first time, too divergent?? could have been buggy)
	
	math_simd.h:
		compare with and without constant refs

	importance sampling
	first-hit rasterization
	GPU compute/RTX path?

Performance: 640x480x128 - Random Scene - Debug-Optimized Build
	
	Base Scalar  : 107s		{48s Release}
	SIMD v3      : 81.5s 	{29s Release}
	Inlining     : 29s		{29s}
	__vectorcall : 29s 		{29s}
	SIMD Spheres : 13s
	XorShift Rand: 11s 

Performance: 640x480x256 - Random 16x Scene - Release Build

	BVH SIMD 	: 32.4s, 31.2s, 31.8s
	LIST SIMD 	: 39.6s, 40s			{128x: 19s}

Notes:
	https://bitshifter.github.io/2018/06/04/simd-path-tracing/
	http://aras-p.info/blog/2018/04/13/Daily-Pathtracer-9-A-wild-ryg-appears/

progressive rendering:
	This is somewhat non-trivial regarding thread scheduling -
	easiest way to avoid load balancing problems would be to spawn a
	task for each sample that renders the whole image at 1x and 
	accumulate these into a float buffer.
	This isn't too hard to implement - just have to spawn all tasks
	and add oGL code for rendering the in-progress float buffer.
	However, note that we can't have many threads writing to the same
	portion of the image at the same time, so would need to synchronize
	(slow) or have a separate buffer for each thread, then composite them
	together.
	For now this isn't really necessary as we can just render the image with
	low samples during scene development, though an "add samples" option would
	be useful.
	So I'll do this when I feel like it.

